# Parser methods: pdfPlumber pyTesseract linux_pdftotext
# You can place OCR methods here to test directly but this is for text extraction methods
[Parser]
method = pdfPlumber

# OCR fallback choices:  pyTesseract ocrmypdf
# place OCR fallback parsing methods here (this is for when text based parsing fails)
[OCR]
fallback = pyTesseract

# AI methods: gpt llama Ollama Ollama/Schema
# Ollama: Solid AI and always json output (Ensure AI Model is chosen)
# gpt: AI gives output, doesn't make JSON 100% of the time
# llama: old and slow! don't use
[AI]
#method = Ollama/Schema
method = vllm
# Ensure you have a model downloaded and insert the name here (Must have Ollama installed too)
    # to download go to "https://ollama.com/library"
    # find a model, grab the model name and parameter amount ex: "qwen2.5-coder:3b"
    # run "ollama run <your_model_name>" in the command line
# AI model methods we've used: qwen2.5-coder:3b, qwen2.5-coder:7b
[Ollama Model]
model = qwen2.5-coder:3b

# the llm prompt, the following are replaced in the prompt
# {filepath} - the uploaded pdfs file path, this sometimes contains context on the document type which helps
# {text} - the text stripped from the pdf returned from the used (or fallback) parsing method
[Prompt]
template = The following text was extracted from a PDF named "{filepath}".\nExtract and categorize the data from the text. Return as JSON.\nText:\n{text}

# Verification
#   running the verification has the ai methods run many times(reruns) and judges the similarity between runs
# active - set to True if you want to run with verification else False
# reruns is the number of times to give the same prompt to the llm and select the most average one of the group for the final output
# threshold is the minimum similarity the chosen output must have to be acceptable
[Verification]
active = False
reruns = 3
threshold = 0.1
